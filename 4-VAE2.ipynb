{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variational Auto Encoder\n",
    "\n",
    "A VAE models complicated distribution through a complex deterministic transformation of a simple distribution. Like many other methods ( one of which was discussed in first notebook ), VAE also tries to maximize the log-likelihood of a sample from the target distribution. Particularly, VAEs maximize the variational lower bound to the log-likelihood. During training phase, it also learns an encoder to estimate the variational lower bound. \n",
    "\n",
    "VAE can be represented by the following :- \n",
    "\n",
    "<img src=\"images/VAE.png\", width=\"900\", align=”left”>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's learn an VAE which generates digits from the MNIST dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "################\n",
    "# import modules\n",
    "################\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gpu or cpu\n",
    "cuda = torch.cuda.is_available()\n",
    "\n",
    "# if gpu is used\n",
    "kwargs = {'num_workers': 1, 'pin_memory': True} if cuda else {}\n",
    "\n",
    "seed = 1\n",
    "\n",
    "# dataset related\n",
    "n_classes = 10\n",
    "z_dim = 2\n",
    "X_dim = 784\n",
    "train_batch_size = 100\n",
    "val_batch_size = train_batch_size\n",
    "N = 1000\n",
    "epochs = 5\n",
    "\n",
    "# load into a dictionary\n",
    "params = {}\n",
    "params['cuda'] = cuda\n",
    "params['n_classes'] = n_classes\n",
    "params['z_dim'] = z_dim\n",
    "params['X_dim'] = X_dim\n",
    "params['train_batch_size'] = train_batch_size\n",
    "params['val_batch_size'] = val_batch_size\n",
    "params['N'] = N\n",
    "params['epochs'] = epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the dataset\n",
    "\n",
    "transform = torchvision.transforms.Compose([\n",
    "    transforms.Normalize((0.1307,),(0.3081,)),\n",
    "    transforms.ToTensor()])\n",
    "\n",
    "train_dataset = torchvision.datasets.MNIST(root='datasets/', \n",
    "                                            train=True, \n",
    "                                            transform=None, \n",
    "                                            target_transform=None, \n",
    "                                            download=True)\n",
    "val_dataset = torchvision.datasets.MNIST(root='datasets/',\n",
    "                                          train=False,\n",
    "                                          transform = None,\n",
    "                                          target_transform=None,\n",
    "                                          download=True)\n",
    "\n",
    "train_labeled_loader = torch.utils.data.DataLoader(train_dataset,\n",
    "                                                   batch_size=train_batch_size,\n",
    "                                                   shuffle=True, **kwargs)\n",
    "val_labeled_loader = torch.utils.data.DataLoader(val_dataset,\n",
    "                                                   batch_size=val_batch_size,\n",
    "                                                   shuffle=True, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining the encoder and decpder networks\n",
    "\n",
    "\n",
    "class QNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(QNet, self).__init__()\n",
    "        self.layer1 = nn.Linear(X_dim, N)\n",
    "        self.layer2 = nn.Linear(N,N)\n",
    "        self.layer3_mean = nn.Linear(N,z_dim)\n",
    "        self.layer3_var = nn.Linear(N,z_dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.dropout(self.layer1, p=0.2)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(self.layer2, p=0.2)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        x_mean = self.layer3_mean(x)\n",
    "        x_var = self.layer3_var(x)\n",
    "        return x_mean, x_var\n",
    "        \n",
    "class PNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(PNet, self).__init__()\n",
    "        self.layer1 = nn.Linear(z_dim, N)\n",
    "        self.layer2 = nn.Linear(N, N)\n",
    "        self.layer3 = nn.Linear(N, X_dim)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.dropout(self.layer1(x), p=0.2)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(self.layer2(x), p=0.2)\n",
    "        x = F.relu(x)\n",
    "        x = F.sigmoid(self.layer3(x))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
