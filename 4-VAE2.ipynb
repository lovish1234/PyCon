{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variational Auto Encoder\n",
    "\n",
    "A VAE models complicated distribution through a complex deterministic transformation of a simple distribution. Like many other methods ( one of which was discussed in first notebook ), VAE also tries to maximize the log-likelihood of a sample from the target distribution. Particularly, VAEs maximize the variational lower bound to the log-likelihood. During training phase, it also learns an encoder to estimate the variational lower bound. \n",
    "\n",
    "VAE can be represented by the following :- \n",
    "\n",
    "<img src=\"images/VAE.png\", width=\"900\", align=”left”>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's learn an VAE which generates digits from the MNIST dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "################\n",
    "# import modules\n",
    "################\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gpu or cpu\n",
    "cuda = torch.cuda.is_available()\n",
    "\n",
    "# if gpu is used\n",
    "kwargs = {'num_workers': 1, 'pin_memory': True} if cuda else {}\n",
    "\n",
    "seed = 1\n",
    "\n",
    "# dataset related\n",
    "n_classes = 10\n",
    "z_dim = 2\n",
    "X_dim = 784\n",
    "train_batch_size = 100\n",
    "val_batch_size = train_batch_size\n",
    "N = 1000\n",
    "epochs = 5\n",
    "\n",
    "# load into a dictionary\n",
    "params = {}\n",
    "params['cuda'] = cuda\n",
    "params['n_classes'] = n_classes\n",
    "params['z_dim'] = z_dim\n",
    "params['X_dim'] = X_dim\n",
    "params['train_batch_size'] = train_batch_size\n",
    "params['val_batch_size'] = val_batch_size\n",
    "params['N'] = N\n",
    "params['epochs'] = epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the dataset\n",
    "\n",
    "transform = torchvision.transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,),(0.3081,))\n",
    "    ])\n",
    "\n",
    "train_dataset = torchvision.datasets.MNIST(root='datasets/', \n",
    "                                            train=True, \n",
    "                                            transform=transform, \n",
    "                                            target_transform=None, \n",
    "                                            download=True)\n",
    "val_dataset = torchvision.datasets.MNIST(root='datasets/',\n",
    "                                          train=False,\n",
    "                                          transform = transform,\n",
    "                                          target_transform=None,\n",
    "                                          download=True)\n",
    "\n",
    "train_data_loader = torch.utils.data.DataLoader(train_dataset,\n",
    "                                                   batch_size=train_batch_size,\n",
    "                                                   shuffle=True, **kwargs)\n",
    "val_data_loader = torch.utils.data.DataLoader(val_dataset,\n",
    "                                                   batch_size=val_batch_size,\n",
    "                                                   shuffle=True, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining the encoder and decoder networks\n",
    "\n",
    "\n",
    "class QNet(nn.Module):\n",
    "    '''\n",
    "    Recoginition Model\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        super(QNet, self).__init__()\n",
    "        self.layer1 = nn.Linear(X_dim, N)\n",
    "        self.layer2 = nn.Linear(N,N)\n",
    "        self.layer3_mean = nn.Linear(N,z_dim)\n",
    "        self.layer3_var = nn.Linear(N,z_dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.dropout(self.layer1(x), p=0.2)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(self.layer2(x), p=0.2)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        x_mean = self.layer3_mean(x)\n",
    "        x_var = self.layer3_var(x)\n",
    "        return x_mean, x_var\n",
    "\n",
    "class PNet(nn.Module):\n",
    "    '''\n",
    "    Generative Model\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        super(PNet, self).__init__()\n",
    "        self.layer1 = nn.Linear(z_dim, N)\n",
    "        self.layer2 = nn.Linear(N, N)\n",
    "        self.layer3 = nn.Linear(N, X_dim)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.dropout(self.layer1(x), p=0.2)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(self.layer2(x), p=0.2)\n",
    "        x = F.relu(x)\n",
    "        x = F.sigmoid(self.layer3(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the previous notebook, we derived the objective that we need to optimise\n",
    "\n",
    "$$ \\mathcal{L}_{ELBO}(q,\\theta)  =  \\int q(z)\\ln\\frac{p(x|z,\\theta)}{q(z)} dz = \\int q(z)\\ln\\frac{p(x|z,\\theta)p(z)}{q(z)} dz  = \\mathbb{E}_{q(z)} [\\ln p(x|z,\\theta)] - KL(q(z)||p(z)) $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train function\n",
    "\n",
    "def train(data_loader, epochs = 10):\n",
    "    \n",
    "    torch.manual_seed(10)\n",
    "\n",
    "    if cuda:\n",
    "        encoder = QNet().cuda()\n",
    "        decoder = PNet().cuda()\n",
    "    else:\n",
    "        encoder = QNet()\n",
    "        decoder = PNet()\n",
    "    \n",
    "    encoder.train()\n",
    "    decoder.train()\n",
    "    \n",
    "    # set the gradient to 0\n",
    "    encoder.zero_grad()\n",
    "    decoder.zero_grad()\n",
    "    \n",
    "    # set a learning rate\n",
    "    lr = 0.0005\n",
    "    \n",
    "    # define a optimiser, usually Adam\n",
    "    encoder_optimiser = optim.Adam(encoder.parameters(), lr=lr)\n",
    "    decoder_optimiser = optim.Adam(decoder.parameters(), lr=lr)\n",
    "    \n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        for i,data in enumerate(data_loader):\n",
    "\n",
    "            # reshape the image from 28x28 to 784\n",
    "            x = data[0].view(-1,784)\n",
    "\n",
    "            # convert to pytorch variable\n",
    "            x = Variable(x)\n",
    "            # convert to gpu mode\n",
    "            if cuda:\n",
    "                x = x.cuda()\n",
    "\n",
    "            # mean a std. of latent distribution\n",
    "\n",
    "            # assume it is log-variance\n",
    "            z_mu, z_sigma = encoder(x)\n",
    "\n",
    "            # converting log variance to variance\n",
    "            z_sigma = (0.5*z_sigma).exp()\n",
    "\n",
    "            # sampling using the reparamatrization trick\n",
    "            epsilon = torch.randn(z_sigma.size())\n",
    "            if cuda:\n",
    "                epsilon = epsilon.cuda()\n",
    "            epsilon = Variable(epsilon)\n",
    "\n",
    "            sample = z_mu+epsilon*z_sigma\n",
    "\n",
    "\n",
    "            # reconstruct through generative network\n",
    "            x_cap = decoder(sample)\n",
    "\n",
    "\n",
    "            # loss function = reconstruction loss + KL divergence loss\n",
    "            # reconstruction loss\n",
    "            criterian = nn.BCELoss()\n",
    "            \n",
    "            recon_loss = criterian(x_cap, x)\n",
    "            \n",
    "            # KL divergence loss\n",
    "            KL_loss = -(0.5)*(1+z_sigma-z_sigma.exp()-z_mu*z_mu)\n",
    "            KL_loss = torch.sum(KL_loss)\n",
    "\n",
    "            total_loss = KL_loss + recon_loss\n",
    "\n",
    "            total_loss.backward()\n",
    "            encoder_optimiser.step()\n",
    "            decoder_optimiser.step()\n",
    "\n",
    "            # ensure that the gradients are reset to zero\n",
    "            encoder.zero_grad()\n",
    "            decoder.zero_grad()\n",
    "            \n",
    "        # print the loss after each epoch \n",
    "        print (\"Epoch: {} Reconstriction Loss : {:.4} KL Divergence Loss : {:.4}\".format(epoch+1, recon_loss.data, KL_loss.data))\n",
    "        \n",
    "    # save the trained encoder and decoder\n",
    "    torch.save(encoder.state_dict(), './models/encoder.pt')\n",
    "    torch.save(decoder.state_dict(), './models/decoder.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Reconstriction Loss : \n",
      "-6. KL Divergence Loss : \n",
      "1.0\n",
      "Epoch: 2 Reconstriction Loss : \n",
      "-6. KL Divergence Loss : \n",
      "1.0\n",
      "Epoch: 3 Reconstriction Loss : \n",
      "-6. KL Divergence Loss : \n",
      "1.0\n",
      "Epoch: 4 Reconstriction Loss : \n",
      "-6. KL Divergence Loss : \n",
      "1.0\n",
      "Epoch: 5 Reconstriction Loss : \n",
      "-6. KL Divergence Loss : \n",
      "1.0\n",
      "Epoch: 6 Reconstriction Loss : \n",
      "-6. KL Divergence Loss : \n",
      "1.0\n",
      "Epoch: 7 Reconstriction Loss : \n",
      "-6. KL Divergence Loss : \n",
      "1.0\n",
      "Epoch: 8 Reconstriction Loss : \n",
      "-6. KL Divergence Loss : \n",
      "1.0\n",
      "Epoch: 9 Reconstriction Loss : \n",
      "-6. KL Divergence Loss : \n",
      "1.0\n",
      "Epoch: 10 Reconstriction Loss : \n",
      "-6. KL Divergence Loss : \n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "train(train_data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reconstruct the images from validation set\n",
    "\n",
    "def reconstruct():\n",
    "    \n",
    "    encoder = QNet()\n",
    "    decoder = PNet()\n",
    "    \n",
    "    if cuda:\n",
    "        encoder = encoder.cuda()\n",
    "        decoder = decoder.cuda()\n",
    "    \n",
    "    encoder.load_state_dict(torch.load('./models/encoder.pt'))\n",
    "    decoder.load_state_dict(torch.load('./models/decoder.pt'))\n",
    "    \n",
    "    \n",
    "    encoder.eval()\n",
    "    decoder.eval()\n",
    "    \n",
    "    for i,data in enumerate(val_data_loader):\n",
    "        break\n",
    "    \n",
    "    # select the first element\n",
    "    \n",
    "    x = data[0].view(-1,784)\n",
    "    x = Variable(x)\n",
    "    if cuda:\n",
    "        x = x.cuda()\n",
    "    \n",
    "    \n",
    "    # sample from the latent distribution\n",
    "    \n",
    "    z_mean, z_sigma = encoder(x)\n",
    "    z_sigma = (0.5*z_sigma).exp()\n",
    "    \n",
    "    epsilon = torch.randn(z_sigma.size())\n",
    "    epsilon = Variable(epsilon)\n",
    "    if cuda:\n",
    "        epsilon = epsilon.cuda()\n",
    "    \n",
    "    sample = z_mean + z_sigma*epsilon\n",
    "    \n",
    "    x_cap = decoder(sample)\n",
    "    \n",
    "    original = x.data.numpy().reshape(-1,28,28)\n",
    "    reconstruction = x_cap.data.numpy().reshape(-1,28,28)\n",
    "        \n",
    "    # plot the images\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.imshow(original[0])\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.imshow(reconstruction[0])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAC7CAYAAAB1qmWGAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10b5f5410>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "reconstruct()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
